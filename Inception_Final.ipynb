{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs\n",
    "from PIL import Image\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pd.read_csv(r\"C:\\Users\\carol\\Desktop\\Adv PM\\train-20181125T003601Z-001\\labels.csv\")\n",
    "target={}\n",
    "for i in labels['id']:\n",
    "    target[i]=labels[labels['id']==i]['breed'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    #Load text files with categories as subfolder names.\n",
    "    images = [f for f in os.listdir(path) if os.path.splitext(f)[-1] == '.jpg']\n",
    "    dog_files=[]\n",
    "    dog_targets=[]\n",
    "    for image in images:\n",
    "        file_id=image.rstrip('.jpg')\n",
    "        dog_files.append(np.array(Image.open(image)))\n",
    "        dog_targets.append(target[file_id])\n",
    "    return dog_files, dog_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_test(path):\n",
    "    #Load text files with categories as subfolder names.\n",
    "    images = [f for f in os.listdir(path) if os.path.splitext(f)[-1] == '.jpg']\n",
    "    dog_files=[]\n",
    "    dog_targets=[]\n",
    "    for image in images:\n",
    "        file_id=image.rstrip('.jpg')\n",
    "        dog_files.append(np.array(Image.open(image)))\n",
    "        #dog_targets.append(target[file_id])\n",
    "    return dog_files#, dog_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2=r\"C:\\Users\\carol\\Desktop\\Adv PM\\train-20181125T003601Z-001\\train\"\n",
    "path3=r\"C:\\Users\\carol\\Desktop\\Adv PM\\test-20181125T004858Z-001\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path2)\n",
    "train_files, train_targets = load_dataset(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path3)\n",
    "test_files = load_dataset_test(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)\n",
    "train_len=len(train_files)\n",
    "indices = np.random.permutation(train_len)\n",
    "train_idx, val_idx = indices[:round(train_len*0.9)], indices[round(train_len*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2=Series(train_targets)\n",
    "y_train, y_val = temp2[train_idx], temp2[val_idx]\n",
    "y_train=list(y_train)\n",
    "y_val=list(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUCATED_IMAGED=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [f for f in os.listdir(path2) if os.path.splitext(f)[-1] == '.jpg']\n",
    "img_pth=[]\n",
    "for i in imgs:\n",
    "    img_pth.append(join(path2,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_img=Series(img_pth)\n",
    "x_train_img, x_val_img = temp_img[train_idx], temp_img[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pth_tr=list(x_train_img)\n",
    "img_pth_vl=list(x_val_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_te = [f for f in os.listdir(path3) if os.path.splitext(f)[-1] == '.jpg']\n",
    "img_pth_te=[]\n",
    "for i in imgs_te:\n",
    "    img_pth_te.append(join(path3,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tensors = paths_to_tensor(img_pth_vl).astype('float32')/255\n",
    "train_tensors = paths_to_tensor(img_pth_tr).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(img_pth_te).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=224\n",
    "num_classes=120\n",
    "S=1\n",
    "train_len=len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_bottleneck=inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "train_i_bf = inception_bottleneck.predict(train_tensors, batch_size=32, verbose=1)\n",
    "valid_i_bf = inception_bottleneck.predict(valid_tensors, batch_size=32, verbose=1)\n",
    "print('InceptionV3 train bottleneck features shape: {} size: {:,}'.format(train_i_bf.shape, train_i_bf.size))\n",
    "print('InceptionV3 valid bottleneck features shape: {} size: {:,}'.format(valid_i_bf.shape, valid_i_bf.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_i_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_i_bf)\n",
    "valid_preds = logreg.predict(valid_i_bf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
